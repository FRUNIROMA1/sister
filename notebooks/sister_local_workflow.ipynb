{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f1151e",
   "metadata": {},
   "source": [
    "# SISTER workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af102d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import IPython\n",
    "\n",
    "# Import warnings module and ignore warnings in output below\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import and initialize MAAP class\n",
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host=\"sister-api.imgspec.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a42bb",
   "metadata": {},
   "source": [
    "### Create unique scene identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f191030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensor': 'PRISMA', 'datetime': '20210730T125208', 'crid': 998, 'preprocess': {'raw_dataset': 'https://sister-ops-workspace.s3.us-west-2.amazonaws.com/prisma/raw/PRS_L1_STD_OFFL_20210730125208_20210730125212_0001.zip', 'landsat_dataset': 'https://sister-ops-workspace.s3.us-west-2.amazonaws.com/prisma/landsat_reference/PRS_20210730125208_20210730125212_0001_landsat.tar.gz'}}\n",
      "{'sensor': 'AVNG', 'datetime': '20210429t190537', 'crid': 998, 'preprocess': {'raw_dataset': 'https://popo.jpl.nasa.gov/avng/y21/ang20210429t190537.tar.gz', 'landsat_dataset': 'None'}}\n",
      "{'sensor': 'AVCL', 'datetime': '20060925T010006', 'crid': 998, 'preprocess': {'raw_dataset': 'https://popo.jpl.nasa.gov/avcl/y06_data/f060925t01p00r06.tar.gz', 'landsat_dataset': 'None'}}\n"
     ]
    }
   ],
   "source": [
    "granules = ['https://sister-ops-workspace.s3.us-west-2.amazonaws.com/prisma/raw/PRS_L1_STD_OFFL_20210730125208_20210730125212_0001.zip',\n",
    "           'https://popo.jpl.nasa.gov/avng/y21/ang20210429t190537.tar.gz',\n",
    "           'https://popo.jpl.nasa.gov/avcl/y06_data/f060925t01p00r06.tar.gz']\n",
    "\n",
    "meta = 'SNOWTESTING'\n",
    "\n",
    "scenes = []\n",
    "\n",
    "crid = 998\n",
    "\n",
    "for l1_granule in granules:\n",
    "    \n",
    "    landsat = 'None'   \n",
    "\n",
    "    base_name = os.path.basename(l1_granule)\n",
    "\n",
    "    if base_name.startswith('DESIS'):\n",
    "        sensor = 'DESIS'\n",
    "        datetime = base_name[31:46]\n",
    "\n",
    "    elif base_name.startswith('PRS'):\n",
    "        sensor = 'PRISMA'\n",
    "        datetime = base_name[16:24] + 'T' + base_name[24:30]\n",
    "        landsat='https://sister-ops-workspace.s3.us-west-2.amazonaws.com/prisma/landsat_reference/PRS_%s_landsat.tar.gz' % base_name[16:50]\n",
    "\n",
    "    elif base_name.startswith('ang'):\n",
    "        sensor = 'AVNG'\n",
    "        datetime = base_name[3:18]\n",
    "\n",
    "    elif base_name.startswith('f'):\n",
    "        sensor = 'AVCL'\n",
    "        ''' AVIRIS classic filenames do not contain acquisition times,to be consistent with other\n",
    "            sensors and to ensure identifier codes are unique a time string is created using other\n",
    "            numbers in the filename            \n",
    "        '''     \n",
    "\n",
    "        datetime = \"20%sT%s%s%s\" % (base_name[1:7],\n",
    "                                    base_name[8:10],\n",
    "                                    base_name[11:13],\n",
    "                                    base_name[14:16])\n",
    "    else:\n",
    "        raise ValueError('Unrecognized L1 datafile')\n",
    "\n",
    "    job_args = {'sensor': sensor,\n",
    "                'datetime': datetime,\n",
    "                 'crid' : crid}\n",
    "    job_args['preprocess'] = {'raw_dataset': l1_granule,\n",
    "                              'landsat_dataset' : landsat}\n",
    "\n",
    "    print(job_args)\n",
    "    \n",
    "    scenes.append(job_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7584d",
   "metadata": {},
   "source": [
    "## Step 1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a716c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier: SISTER_PRISMA_L1B_RDN_20210730T125208_998_SNOWTESTING\n",
      "Submission status: success\n",
      "Job ID: 625efa07-6986-4235-a4f4-9fd2b4f1de4f\n",
      "Identifier: SISTER_AVNG_L1B_RDN_20210429t190537_998_SNOWTESTING\n",
      "Submission status: success\n",
      "Job ID: 9c08bed6-3435-4246-8013-c43f039ef211\n",
      "Identifier: SISTER_AVCL_L1B_RDN_20060925T010006_998_SNOWTESTING\n",
      "Submission status: success\n",
      "Job ID: cf8ab819-be02-4d6f-bddd-f3ce13b8bf82\n"
     ]
    }
   ],
   "source": [
    "for i,scene in enumerate(scenes):\n",
    "        \n",
    "    if scene['sensor'] == 'AVCL':\n",
    "        queue=\"sister-job_worker-32gb\"\n",
    "    else:\n",
    "        queue=\"sister-job_worker-16gb\"\n",
    "    \n",
    "    identifier = f'SISTER_{scene[\"sensor\"]}_L1B_RDN_{scene[\"datetime\"]}_{scene[\"crid\"]}_{meta}'\n",
    "    \n",
    "    preprocess_job_response = maap.submitJob(\n",
    "        algo_id = \"sister-preprocess\",\n",
    "        version = \"sister-dev\",\n",
    "        raw_dataset = scene['preprocess']['raw_dataset'],\n",
    "        landsat_dataset = scene['preprocess']['landsat_dataset'],\n",
    "        crid = scene['crid'],\n",
    "        publish_to_cmr = False,\n",
    "        cmr_metadata={},\n",
    "        queue=queue,\n",
    "        identifier= identifier)\n",
    "\n",
    "    print(f'Identifier: {identifier}')\n",
    "    print(f'Submission status: {preprocess_job_response.status}')\n",
    "    print(f'Job ID: {preprocess_job_response.id}')\n",
    "          \n",
    "    scenes[i]['preprocess']['job_id'] = preprocess_job_response.id\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d3b77",
   "metadata": {},
   "source": [
    "## Step 2. ISOFIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "565fa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,scene in enumerate(scenes):\n",
    "        \n",
    "    if scene['sensor'] == 'AVCL':\n",
    "        segmentation_size = 100\n",
    "    else:\n",
    "        segmentation_size = 100\n",
    "    \n",
    "    identifier = f'SISTER_{scene[\"sensor\"]}_L2A_RFL_{scene[\"datetime\"]}_{scene[\"crid\"]}_{meta}'\n",
    "    \n",
    "    preprocess_id = scene['preprocess']['job_id'] \n",
    "    \n",
    "    preprocess_result= [ x for x in maap.getJobResult(preprocess_id).outputs if x.startswith(\"s3://s3.\") and \"RDN\" in x]\n",
    "    preprocess_result.sort()\n",
    "    l1b_rdn,l1b_loc, l1b_obs = preprocess_result\n",
    "    \n",
    "    scene['preprocess']['radiance_dataset'] =l1b_rdn\n",
    "    scene['preprocess']['location_dataset'] =l1b_loc\n",
    "    scene['preprocess']['observation_dataset'] =l1b_obs\n",
    "\n",
    "    isofit_job_response = maap.submitJob(\n",
    "                                    algo_id=\"sister-isofit\",\n",
    "                                    version=\"sister-dev\",\n",
    "                                    radiance_dataset=l1b_rdn,\n",
    "                                    location_dataset = l1b_loc,\n",
    "                                    observation_dataset = l1b_obs,\n",
    "                                    segmentation_size = segmentation_size,\n",
    "                                    n_cores=32,\n",
    "                                    crid = scene['crid'],\n",
    "                                    publish_to_cmr=False,\n",
    "                                    cmr_metadata={},\n",
    "                                    queue=\"sister-job_worker-32gb\",\n",
    "                                    identifier= identifier)\n",
    "\n",
    "    print(f'Identifier: {identifier}')\n",
    "    print(f'Submission status: {isofit_job_response.status}')\n",
    "    print(f'Job ID: {isofit_job_response.id}')\n",
    "    \n",
    "    scene['isofit']  = {'job_id' : isofit_job_response.id}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d12bd",
   "metadata": {},
   "source": [
    "## Step 3. Spectral resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e21aeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier: SISTER_AVNG_L2A_RSRFL_20170820t182018_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 93725a9f-c9e2-43bc-aa74-b4b1745d749c\n",
      "Identifier: SISTER_AVCL_L2A_RSRFL_20130815T010007_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 08f4dd77-2828-4a28-9425-57dc0561f41d\n",
      "Identifier: SISTER_PRISMA_L2A_RSRFL_20220409T185601_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 8d2e4f86-825b-4ac5-a955-3a73d18bfbdf\n",
      "Identifier: SISTER_DESIS_L2A_RSRFL_20211120T035820_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 032ca4a1-c706-4299-9622-f54591147348\n"
     ]
    }
   ],
   "source": [
    "for i,scene in enumerate(scenes):\n",
    "\n",
    "    identifier = f'SISTER_{scene[\"sensor\"]}_L2A_RSRFL_{scene[\"datetime\"]}_{scene[\"crid\"]}_{meta}'\n",
    "    \n",
    "    isofit_id = scene['isofit']['job_id'] \n",
    "\n",
    "    iso_result= [ x for x in maap.getJobResult(isofit_id).outputs if x.startswith(\"s3://s3.\") and \"RFL\" in x]\n",
    "    l2a_rfl,l2a_unc = iso_result\n",
    "        \n",
    "    scene['isofit']['reflectance_dataset'] =l2a_rfl\n",
    "    scene['isofit']['uncertainty_dataset'] =l2a_unc\n",
    "\n",
    "    resample_job_response = maap.submitJob(\n",
    "                                            algo_id=\"sister-resample\",\n",
    "                                            version=\"sister-dev\",\n",
    "                                            reflectance_dataset= l2a_rfl,\n",
    "                                            uncertainty_dataset= l2a_unc,\n",
    "                                            crid = scene['crid'],\n",
    "                                            publish_to_cmr=False,\n",
    "                                            cmr_metadata={},\n",
    "                                            queue=\"sister-job_worker-16gb\",\n",
    "                                            identifier=identifier)\n",
    "\n",
    "    print(f'Identifier: {identifier}')\n",
    "    print('Submission status: %s' % resample_job_response.status)\n",
    "    print('Job ID: %s' % resample_job_response.id)\n",
    "    scene['resample']  = {'job_id' : resample_job_response.id}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6701e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "efb10ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier: SISTER_PRISMA_L2A_CORFL_20220409T185601_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: dec00bb0-3f2f-4026-a044-ddc53d361436\n",
      "Identifier: SISTER_DESIS_L2A_CORFL_20211120T035820_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 5a77f9bf-0862-4632-a26d-450dc0854c15\n"
     ]
    }
   ],
   "source": [
    "for i,scene in enumerate(scenes):\n",
    "\n",
    "    identifier = f'SISTER_{scene[\"sensor\"]}_L2A_CORFL_{scene[\"datetime\"]}_{scene[\"crid\"]}_{meta}'\n",
    "    \n",
    "    resample_id = scene['resample']['job_id'] \n",
    "    resample_result= [ x for x in maap.getJobResult(resample_id).outputs if x.startswith(\"s3://s3.\") and \"RSRFL\" in x]\n",
    "    l2a_rsrfl,l2a_rsunc = resample_result\n",
    "    \n",
    "    scene['resample']['reflectance_dataset'] =l2a_rsrfl\n",
    "    scene['resample']['uncertainty_dataset'] =l2a_rsunc\n",
    "\n",
    "\n",
    "\n",
    "    rfl_corr_job_response = maap.submitJob(\n",
    "                                            algo_id=\"sister-reflect_correct\",\n",
    "                                            version=\"sister-dev\",\n",
    "                                            observation_dataset= scene['preprocess']['observation_dataset'],\n",
    "                                            reflectance_dataset= l2a_rsrfl,\n",
    "                                            crid = scene['crid'],\n",
    "                                            publish_to_cmr=False,\n",
    "                                            cmr_metadata={},\n",
    "                                            queue=\"sister-job_worker-16gb\",\n",
    "                                            identifier=identifier)\n",
    "\n",
    "    print(f'Identifier: {identifier}')\n",
    "    print('Submission status: %s' % rfl_corr_job_response.status)\n",
    "    print('Job ID: %s' % rfl_corr_job_response.id)\n",
    "    scene['reflect_correct']  = {'job_id' : rfl_corr_job_response.id}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31719b9b",
   "metadata": {},
   "source": [
    "## Step 4. Fractional Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4fb79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier: SISTER_AVNG_L2B_FRCOV_20170820t182018_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 62b86363-bed0-459e-aabe-fca4de060f78\n",
      "Identifier: SISTER_AVCL_L2B_FRCOV_20130815T010007_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: f5a82cea-2441-47ea-a568-2134538decd5\n",
      "Identifier: SISTER_PRISMA_L2B_FRCOV_20220409T185601_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: a1764c1f-5960-4a7d-b5ea-0ccceb3854c1\n",
      "Identifier: SISTER_DESIS_L2B_FRCOV_20211120T035820_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: b51efbc7-2c3c-47e9-a161-f7444c15bf4a\n"
     ]
    }
   ],
   "source": [
    "for i,scene in enumerate(scenes):\n",
    "\n",
    "    identifier = f'SISTER_{scene[\"sensor\"]}_L2B_FRCOV_{scene[\"datetime\"]}_{scene[\"crid\"]}_{meta}'\n",
    "    \n",
    "    correct_id = scene['reflect_correct']['job_id'] \n",
    "    correct_result= [ x for x in maap.getJobResult(correct_id).outputs if x.startswith(\"s3://s3.\") and \"CORFL\" in x]\n",
    "    l2a_corfl =  correct_result[0]\n",
    "    scene['reflect_correct']['reflectance_dataset'] = l2a_corfl\n",
    "\n",
    "    frcover_job_response = maap.submitJob(\n",
    "                                        algo_id=\"sister-fractional-cover\",\n",
    "                                        version=\"sister-dev\",\n",
    "                                        l2a_rfl=l2a_corfl,\n",
    "                                        n_cores= 20,\n",
    "                                        refl_nodata = -9998,\n",
    "                                        refl_scale= 1,\n",
    "                                        normalization = 'brightness',\n",
    "                                        crid = scene['crid'],\n",
    "                                        publish_to_cmr=False,\n",
    "                                        cmr_metadata={},\n",
    "                                        queue=\"sister-job_worker-32gb\",\n",
    "                                        identifier= identifier)\n",
    "\n",
    "    print(f'Identifier: {identifier}')\n",
    "    print('Submission status: %s' % frcover_job_response.status)\n",
    "    print('Job ID: %s' % frcover_job_response.id)\n",
    "    scene['frcover']  = {'job_id' : frcover_job_response.id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c53cca",
   "metadata": {},
   "source": [
    "## Step 6a. Vegetation biochemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1bb09888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier: SISTER_AVNG_L2B_VEGBIOCHEM_20170820t182018_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 94e23f01-c4d2-4a6d-b94e-7ffb94392255\n",
      "Identifier: SISTER_AVCL_L2B_VEGBIOCHEM_20130815T010007_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 79b7d17f-3c81-4c69-bb03-eab1c30ef66e\n",
      "Identifier: SISTER_PRISMA_L2B_VEGBIOCHEM_20220409T185601_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: 61157bcd-cfb8-4a4c-822a-f2a877ef7862\n",
      "Identifier: SISTER_DESIS_L2B_VEGBIOCHEM_20211120T035820_999_TESTING\n",
      "Submission status: success\n",
      "Job ID: e2b4af88-4877-420c-91f6-162132bc600a\n"
     ]
    }
   ],
   "source": [
    "for i,scene in enumerate(scenes):\n",
    "\n",
    "    identifier = f'SISTER_{scene[\"sensor\"]}_L2B_VEGBIOCHEM_{scene[\"datetime\"]}_{scene[\"crid\"]}_{meta}'\n",
    "    \n",
    "    frcover_id = scene['frcover']['job_id'] \n",
    "    frcover_result= [x for x in maap.getJobResult(frcover_id).outputs if x.startswith(\"s3://s3.\") and \"FRCOV\" in x]\n",
    "    l2b_frcov =  frcover_result[0]                   \n",
    "    scene['frcover']['frcover_dataset'] = l2b_frcov\n",
    "\n",
    "    vegbiochem_job_response = maap.submitJob(\n",
    "                            algo_id=\"sister-trait_estimate\",\n",
    "                            version=\"sister-dev\",\n",
    "                            reflectance_dataset= scene['reflect_correct']['reflectance_dataset'],\n",
    "                            frcov_dataset=l2b_frcov,\n",
    "                            veg_cover = 0.5,\n",
    "                            crid = scene['crid'],\n",
    "                            publish_to_cmr=False,\n",
    "                            cmr_metadata={},\n",
    "                            queue=\"sister-job_worker-16gb\",\n",
    "                            identifier=identifier)\n",
    "\n",
    "    print(f'Identifier: {identifier}')\n",
    "    print('Submission status: %s' % vegbiochem_job_response.status)\n",
    "    print('Job ID: %s' % vegbiochem_job_response.id)\n",
    "    scene['vegbiochem']  = {'job_id' : vegbiochem_job_response.id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728f5e5",
   "metadata": {},
   "source": [
    "## Step 6b. Snow grainsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c62d121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission status: success\n",
      "Job ID: cc97aa3b-bca6-45bc-8cc5-22b11d52703f\n"
     ]
    }
   ],
   "source": [
    "grainsize_job_response = maap.submitJob(\n",
    "    algo_id=\"sister-grainsize\",\n",
    "    version=\"sister-dev\",\n",
    "    l2a_rfl=l2a_corfl,\n",
    "    l2b_frcov=l2b_frcov,\n",
    "    snow_cover = 0.9,\n",
    "    CRID= '123',\n",
    "    publish_to_cmr=False,\n",
    "    cmr_metadata={},\n",
    "    queue=\"sister-job_worker-32gb\",\n",
    "    identifier=\"%s_L2B_SNOWTEST\" % identifier)\n",
    "\n",
    "print('Submission status: %s' % grainsize_job_response.status)\n",
    "print('Job ID: %s' % grainsize_job_response.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bda35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
